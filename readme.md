# Goal: To implement machine learning models and algorithms from scratch.

# Rules:
1. Only using python and math and matrix multiplication libraries like math and numpy. Can also use helper 2. libraries such as tqdm and matplotlib.
3. No use of Pytorch, Tensorflow, JAX, autograd, etc.
4. No use of LLMs to generate code.
5. LLMs can only be used to ideate and understand logic and concepts. Every line of code must be written manually.
6. Mention the source of code and documentation if referenced inside comments.
7. Document everything.

## Existing repos/blogs/resources that share the goal:
 - https://github.com/gmontamat/poor-mans-transformers (very good reference resource)
	- has documented everything for future reference.
 - https://github.com/eriklindernoren/ML-From-Scratch (god resource, follow this)
	-has covered everything from simple regression to deep Q learning and GANs
 - https://dafriedman97.github.io/mlbook/content/introduction.html


## Rough Plan (built with help from GPT)

Phase 0   
Linear algebra, regression, perceptron, loss functions (MSE, binary cross entropy), basic optimizers (vanilla gradient descent)

Phase 1   
Classic ML algorithms (kNN, Naive Bayes, SVM, Decision Trees, Random Forests, k-means, PCA)

Phase 2   
Neural networks (without autogrid, backdrop by hand), dense layers, activation functions (ReLU, sigmoid, tanh), losses

Phase 3   
Computation graph, automatic gradient propagation (tensor abstraction, operations and engine)

Phase 4   
Deep Learning blocks (LayerNorm, BatchNorm, Dropout), better optimizers (Adam, RMSProp)

Phase 5    
Sequence models (BoW, RNN, LSTM, GRU)

Phase 6    
Attention and Transformers

Note: Phases can vary. Additional concepts or models could be added. 


